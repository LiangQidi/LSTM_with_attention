{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence#, masked_cross_entropy\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import  math\n",
    "import  torch\n",
    "import  random\n",
    "from  torch  import  nn\n",
    "from  torch.autograd  import Variable\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "from torchtext import datasets\n",
    "from torchtext import data\n",
    "from torchtext.datasets import Multi30k, LanguageModelingDataset\n",
    "from torchtext.data import Field, BucketIterator, Iterator\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "class tokenize(object):\n",
    "    \n",
    "    def __init__(self, lang):\n",
    "        self.nlp = spacy.load(lang)\n",
    "            \n",
    "    def tokenizer(self, sentence):\n",
    "        sentence = re.sub(\n",
    "        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n",
    "        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n",
    "        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n",
    "        sentence = re.sub(r\"\\,+\", \",\", sentence)\n",
    "        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n",
    "        return [tok.text for tok in self.nlp.tokenizer(sentence) if tok.text != \" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_fr = tokenize('fr')\n",
    "tokenize_en = tokenize('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FR_TEXT = data.Field(lower=True, tokenize=tokenize_fr.tokenizer, init_token='<sos>', eos_token='<eos>')\n",
    "EN_TEXT = data.Field(lower=True, tokenize=tokenize_en.tokenizer, init_token='<sos>', eos_token='<eos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafields = [(\"French\", FR_TEXT), (\"English\", EN_TEXT)]\n",
    "tr, v = data.TabularDataset.splits(path='./', train=\"train.csv\", validation=\"val.csv\", format = \"csv\", fields=datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FR_TEXT.build_vocab(tr, v)\n",
    "EN_TEXT.build_vocab(tr, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "datafields = [(\"id\", None), (\"French\", FR_TEXT), (\"English\", EN_TEXT)]\n",
    "trn = TabularDataset(\"French.csv\", format='csv', fields=datafields)\n",
    "\n",
    "FR_TEXT.build_vocab(trn)\n",
    "EN_TEXT.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "md = BucketIterator(tr, batch_size=batch_size, sort_key=lambda x: len(x.English), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(batch_size):\n",
    "    \n",
    "    batch = next(iter(md))\n",
    "      \n",
    "    input_batch = batch.English[1:].cuda()\n",
    "    target_batch = batch.French[1:].cuda()\n",
    "    \n",
    "    target_lengths = []\n",
    "    input_lengths = []\n",
    "    \n",
    "    input_tp = input_batch.transpose(0,1).data.cpu().numpy()\n",
    "    target_tp = target_batch.transpose(0,1).data.cpu().numpy()\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        target_lengths.append(int(np.where(target_tp[i] == 3)[0][0] + 1))\n",
    "        input_lengths.append(int(np.where(input_tp[i] == 3)[0][0] + 1))\n",
    "    \n",
    "   \n",
    "    p = list(np.array((input_batch.data.transpose(0,1) == 3).nonzero()[:,1]))\n",
    "    return input_batch, input_lengths, target_batch, target_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 2\n",
    "EOS_token = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=1)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n",
    "        \n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        # Note: we run this all at once (over multiple batches of multiple sequences)\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        #packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(embedded, hidden)\n",
    "        #outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN_mine(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_size, n_layers = 1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size, padding_idx=1)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout, bidirectional=True)\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def forward(self, word_input, batch_size, hidden=None):\n",
    "        seq_len = len(word_input)\n",
    "        \n",
    "        embedded = self.embedding(word_input)\n",
    "        outputs, hidden = self.gru(embedded, hidden)\n",
    "        encoder_out = outputs[:,:,:self.hidden_size] + outputs[:,:,self.hidden_size:]\n",
    "        return encoder_out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, output_size, embedding_size, hidden_size, dropout_p = 0.1, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size, padding_idx=1)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.attn = nn.Linear(hidden_size, hidden_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.n_layers = n_layers\n",
    "        self.attn_combine = nn.Linear(hidden_size + embedding_size, hidden_size)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def score(self, rnn_output, e_outputs):\n",
    "        energy = self.attn(e_outputs)\n",
    "        energy = energy.transpose(0,1).transpose(1,2)\n",
    "        rnn_output = rnn_output.transpose(0,1)\n",
    "        energy = (rnn_output @ energy).squeeze(1)\n",
    "        \n",
    "        return F.softmax(energy, dim=1).unsqueeze(1)\n",
    "    \n",
    "    def forward(self, input_seq, hidden, e_outputs, batch_size):\n",
    "        embed = self.dropout(self.embedding(input_seq)).view(1, batch_size, -1)\n",
    "        rnn_output, hidden = self.gru(embed, hidden)\n",
    "        attn_weights = self.score(rnn_output, e_outputs)\n",
    "        context = attn_weights.bmm(e_outputs.transpose(0, 1))\n",
    "        concat = torch.cat((rnn_output.squeeze(0), context.squeeze(1)), 1)\n",
    "        concat = F.tanh(self.concat(concat))\n",
    "        output = self.out(concat)\n",
    "        \n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure models\n",
    "attn_model = 'dot'\n",
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 100\n",
    "batch_size = 50\n",
    "\n",
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_epochs = 50000\n",
    "epoch = 0\n",
    "plot_every = 20\n",
    "print_every = 100\n",
    "evaluate_every = 1000\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN_mine(len(EN_TEXT.vocab), hidden_size, n_layers, dropout=dropout)\n",
    "#decoder = LuongAttnDecoderRNN(attn_model, hidden_size, output_lang.n_words, n_layers, dropout=dropout)\n",
    "decoder = LuongAttnDecoder(len(FR_TEXT.vocab), hidden_size, hidden_size, dropout_p=dropout, n_layers=2)\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_batches, input_lengths, target_batches, target_lengths, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "   \n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    max_target_length = int(max(target_lengths))\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_target_length, batch_size, decoder.output_size))\n",
    "\n",
    "    # Move new Variables to CUDA\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "\n",
    "    # Run through decoder one time step at a time\n",
    "    for t in range(max_target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs, batch_size\n",
    "        )\n",
    "\n",
    "        all_decoder_outputs[t] = decoder_output\n",
    "        decoder_input = target_batches[t] # Next input is current target\n",
    "\n",
    "    # Loss calculation and backpropagation\n",
    "    #loss = masked_cross_entropy(\n",
    "     #   all_decoder_outputs.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "      #  target_batches.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "       # target_lengths\n",
    "    #)\n",
    "    loss = F.cross_entropy(all_decoder_outputs.view(-1, all_decoder_outputs.size(2)),\n",
    "                           target_batches.view(-1), ignore_index=1)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip gradient norms\n",
    "    ec = torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    dc = torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "\n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0], ec, dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "n_epochs = 150000\n",
    "# Begin!# Begin!\n",
    "ecs = []\n",
    "dcs = []\n",
    "eca = 0\n",
    "dca = 0\n",
    "\n",
    "while epoch < n_epochs:\n",
    "    epoch += 1\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    input_batches, input_lengths, target_batches, target_lengths = random_batch(batch_size)\n",
    "\n",
    "    # Run the train function\n",
    "    loss, ec, dc = train(\n",
    "        input_batches, input_lengths, target_batches, target_lengths,\n",
    "        encoder, decoder,\n",
    "        encoder_optimizer, decoder_optimizer, criterion\n",
    "    )\n",
    "    \n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "    eca += ec\n",
    "    dca += dc\n",
    "    \n",
    "   \n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), \"./data/encoder_att_best_20m\")\n",
    "torch.save(decoder.state_dict(), \"./data/decoder_att_best_20m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, translation):\n",
    "        input_sentence = ' '.join([EN_TEXT.vocab.itos[ix] for ix in sentence.transpose(0, 1).squeeze(0).data])\n",
    "        translation = ' '.join([FR_TEXT.vocab.itos[ix] for ix in translation.transpose(0, 1).squeeze(0).data])\n",
    "        print('+ ' + input_sentence + '\\n= ' + translation)\n",
    "       \n",
    "        output_sentence = []\n",
    "         \n",
    "        encoder_outputs, hidden = encoder(sentence, input_lengths)\n",
    "    \n",
    "        d_input = Variable(torch.LongTensor([SOS_token]).view(1,1).cuda())\n",
    "        d_hidden = hidden[:decoder.n_layers]\n",
    "        \n",
    "        \n",
    "    \n",
    "        for i in range(30):\n",
    "            d_output, d_hidden, attn_weights = decoder(d_input, d_hidden, encoder_outputs, 1)\n",
    "        \n",
    "            val, ix = d_output.data.topk(1)\n",
    "           \n",
    "            if ix[0][0] == EOS_token:\n",
    "                    break\n",
    "            \n",
    "            output_sentence.append(FR_TEXT.vocab.itos[ix[0][0]])\n",
    "            d_input = Variable(torch.LongTensor([ix[0][0]]).cuda())\n",
    "            \n",
    "        print('> ' + ' '.join(output_sentence) + '\\n')\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_md = BucketIterator(v, batch_size=1, sort_key=lambda x: len(x.French), shuffle=True)\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    example = next(iter(eval_md))\n",
    "    translate(example.English[1:], example.French[1:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
